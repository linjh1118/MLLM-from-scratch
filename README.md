<div align=center>
  <h1>MLLM-from-scratch</h1>
</div>


&emsp;简单来说，本项目(多模态大模型部署微调指南)将助力你掌握：各种MLLM的部署/微调/结合Agent/源码学习等。

&emsp;&emsp;本项目的主要内容包括：
  1. MLLM 的 部署教程，包括 CogVLM2、LLaMA3.2、Qwen2VL、InternVL 等； 
  2. MLLM 的 调用教程，包括命令行调用、在线 Demo 部署等；
  3. MLLM 的 微调教程(全量/Peft)


<div align=center>
  <h2>Advice</h2>
</div>

> &emsp;&emsp; 本项目可以看作是[self-llm](https://github.com/datawhalechina/self-llm)的多模态拓展版本，感谢[KMnO4-zx](https://github.com/KMnO4-zx)的卓越贡献。

> &emsp;&emsp;***学习建议：挑选自己感兴趣的模型，跟着教程学习其部署/微调，之后可以去[hugginface的datasets](https://huggingface.co/datasets)上，找一些有意思的数据集微调下。***



> 注：如果有同学希望了解大模型的模型构成，以及从零手写RAG、Agent和Eval等任务，可以学习Datawhale的另一个项目[Tiny-Universe](https://github.com/datawhalechina/tiny-universe)，大模型是当下深度学习领域的热点，但现有的大部分大模型教程只在于教给大家如何调用api完成大模型的应用，而很少有人能够从原理层面讲清楚模型结构、RAG、Agent 以及 Eval。所以该仓库会提供全部手写，不采用调用api的形式，完成大模型的 RAG 、 Agent 、Eval 任务。

> 注：考虑到有同学希望在学习本项目之前，希望学习大模型的理论部分，如果想要进一步深入学习 LLM 的理论基础，并在理论的基础上进一步认识、应用 LLM，可以参考 Datawhale 的 [so-large-llm](https://github.com/datawhalechina/so-large-lm.git)课程。

> 注：如果有同学在学习本课程之后，想要自己动手开发大模型应用。同学们可以参考 Datawhale 的 [动手学大模型应用开发](https://github.com/datawhalechina/llm-universe) 课程，该项目是一个面向小白开发者的大模型应用开发教程，旨在基于阿里云服务器，结合个人知识库助手项目，向同学们完整的呈现大模型应用开发流程。


<div align=center>
  <h2>Connect or Join us</h2>
</div>
> &emsp;&emsp;想要深度参与的同学可以通过[我的主页](https://github.com/linjh1118) 联系我，我会将你加入到项目的维护者中。
